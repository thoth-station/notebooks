{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial recommendation engine design (PoC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "import logging\n",
    "from enum import Enum\n",
    "from enum import auto\n",
    "\n",
    "_LOGGER = logging.getLogger(__name__)\n",
    "logging.basicConfig()\n",
    "_LOGGER.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importable</th>\n",
       "      <th>package</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>thoth.adviser</td>\n",
       "      <td>0.0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>thoth.analyzer</td>\n",
       "      <td>0.0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>thoth.common</td>\n",
       "      <td>0.0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>thoth.lab</td>\n",
       "      <td>0.0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>thoth.package_extract</td>\n",
       "      <td>1.0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>True</td>\n",
       "      <td>thoth.solver</td>\n",
       "      <td>1.0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>True</td>\n",
       "      <td>thoth.storages</td>\n",
       "      <td>0.0.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  importable                package version\n",
       "0       True          thoth.adviser   0.0.2\n",
       "1       True         thoth.analyzer   0.0.5\n",
       "2       True           thoth.common   0.0.3\n",
       "3       True              thoth.lab   0.0.3\n",
       "4       True  thoth.package_extract   1.0.0\n",
       "5       True           thoth.solver   1.0.2\n",
       "6       True         thoth.storages  0.0.16"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from thoth.lab import packages_info\n",
    "# Show working environment to have this reproducible.\n",
    "packages_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use utilities already present in the Thoth's code base. We will also use internal API of `pip`. Note that you need to have installed `pip<10` as API changed recently with release 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thoth.solver import pip_compile\n",
    "from pip._vendor.packaging.requirements import Requirement\n",
    "from pip._vendor.packaging.specifiers import SpecifierSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will provide three basic recommendations:\n",
    "\n",
    "  1. **STABLE** - based on knowledge we have, we know that the given software stack will work in the given environmnet\n",
    "  2. **TESTING** - exclude packages that can cause errors, leave packages for which we don't have information about (testing their behavior in a software stack)\n",
    "  3. **LATEST** - always a bleeding edge software stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommendationType(Enum):\n",
    "    STABLE = auto()\n",
    "    TESTING = auto()\n",
    "    LATEST = auto()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In examples in this notebook we will be assuming we request `flask` and `tensorflow` in our software stack. This input can directly come from `requirements.txt` so it is ok to put even version specifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_requirements = \"\"\"\n",
    "tensorflow\n",
    "flask>=1.0\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We leave the resolution logic on `pip-compile` that resolves the given software stack and provides full pinned-down software stack specification for Python packages that are direct or transitive dependencies of our requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#\n",
      "# This file is autogenerated by pip-compile\n",
      "# To update, run:\n",
      "#\n",
      "#    pip-compile --output-file requirements.txt requirements.in\n",
      "#\n",
      "absl-py==0.2.2            # via tensorflow\n",
      "astor==0.6.2              # via tensorflow\n",
      "bleach==1.5.0             # via tensorboard\n",
      "click==6.7                # via flask\n",
      "flask==1.0.2\n",
      "gast==0.2.0               # via tensorflow\n",
      "grpcio==1.12.0            # via tensorflow\n",
      "html5lib==0.9999999       # via bleach, tensorboard\n",
      "itsdangerous==0.24        # via flask\n",
      "jinja2==2.10              # via flask\n",
      "markdown==2.6.11          # via tensorboard\n",
      "markupsafe==1.0           # via jinja2\n",
      "numpy==1.14.3             # via tensorboard, tensorflow\n",
      "protobuf==3.5.2.post1     # via tensorboard, tensorflow\n",
      "six==1.11.0               # via absl-py, bleach, grpcio, html5lib, protobuf, tensorboard, tensorflow\n",
      "tensorboard==1.8.0        # via tensorflow\n",
      "tensorflow==1.8.0\n",
      "termcolor==1.1.0          # via tensorflow\n",
      "werkzeug==0.14.1          # via flask, tensorboard\n",
      "wheel==0.31.1             # via tensorboard, tensorflow\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pip_compile(*raw_requirements.splitlines()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will directly reuse logic offered by pip to correctly parse packages from their textual representation considering version ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_requirements(requiremnets: str) -> typing.List[Requirement]:\n",
    "    return [Requirement(req) for req in raw_requirements.splitlines() if req and not req.strip().startswith('#')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For demonstration purposes, let's parse our initial software stack requirements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Requirement('tensorflow')>, <Requirement('flask>=1.0')>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_requirements = parse_requirements(raw_requirements)\n",
    "parsed_requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume we have a knowledge base that stores information about a package in its version (package-version level information). In this example our knowledge base states if the given package is good (`True`) or bad (`False` - meaning errors such as installation error into the requested environment). If there is no package record it means we don't have any observations for the given package that could be used for recommendations. This is especially usefull for the `TESTING` recommendation type in which we add such packages to our software stack (e.g. testing purposes, no stable version for the given software stack)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNOWLEDGE_BASE = {\n",
    "    'absl-py==0.2.2': True,\n",
    "    'astor==0.6.2': True,\n",
    "    'bleach==1.5.0': True,\n",
    "    'click==6.7': True,\n",
    "    'flask==1.0.2': True,\n",
    "    'gast==0.2.0': True,\n",
    "    'grpcio==1.12.0': True,\n",
    "    'html5lib==0.9999999': True,\n",
    "    'itsdangerous==0.24': True,\n",
    "    'jinja2==2.10': True,\n",
    "    'markdown==2.6.11': True,\n",
    "    'markupsafe==1.0': True,\n",
    "    'numpy==1.14.3': True,\n",
    "    'protobuf==3.5.2.post1': True,\n",
    "    'six==1.11.0': True,\n",
    "    'tensorboard==1.8.0': False,\n",
    "    'tensorboard==1.7.0': True,\n",
    "    'tensorflow==1.7.0': True,\n",
    "    'tensorflow==1.7.1': None,\n",
    "    'termcolor==1.1.0': True,\n",
    "    'werkzeug==0.14.1': True,\n",
    "    'wheel==0.31.1': True,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we use pip's internal requirement and specification abstractions, let's create a wrapper around `pip-compile` that will prepare input for pip-compile and parse its output so we keep parsed requirements as Python objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "\n",
    "def _get_from_dependencies(comment: str):\n",
    "    result = []\n",
    "    \n",
    "    comment = comment[len('via '):]\n",
    "    for dep in comment.split(','):\n",
    "        result.append(dep.strip())\n",
    "\n",
    "    return result\n",
    "\n",
    "def execute_pip_compile(*requirements: Requirement) -> typing.List[Requirement]:\n",
    "    result = []\n",
    "    graph = {}\n",
    "    \n",
    "    output = pip_compile(*[str(req) for req in requirements])\n",
    "    for line in output.splitlines():\n",
    "        if line.startswith('#'):\n",
    "            # Skip leading pip-compile comments.\n",
    "            continue\n",
    "        line = line.split('#', maxsplit=1)\n",
    "        \n",
    "        if len(line) == 2:\n",
    "            requirement, comment = line\n",
    "            requirement = Requirement(requirement)\n",
    "            result.append(requirement)\n",
    "            \n",
    "            from_dependencies = _get_from_dependencies(comment)\n",
    "            graph[requirement.name] = from_dependencies\n",
    "        else:\n",
    "            requirement = Requirement(line[0])\n",
    "            result.append(requirement)\n",
    "            # This is root node.\n",
    "            graph[requirement.name] = []\n",
    "        \n",
    "    return result, graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's perform `pip-compile` on our initial software stack requirements that are already parsed into Python objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<Requirement('absl-py==0.2.2')>,\n",
       "  <Requirement('astor==0.6.2')>,\n",
       "  <Requirement('bleach==1.5.0')>,\n",
       "  <Requirement('click==6.7')>,\n",
       "  <Requirement('flask==1.0.2')>,\n",
       "  <Requirement('gast==0.2.0')>,\n",
       "  <Requirement('grpcio==1.12.0')>,\n",
       "  <Requirement('html5lib==0.9999999')>,\n",
       "  <Requirement('itsdangerous==0.24')>,\n",
       "  <Requirement('jinja2==2.10')>,\n",
       "  <Requirement('markdown==2.6.11')>,\n",
       "  <Requirement('markupsafe==1.0')>,\n",
       "  <Requirement('numpy==1.14.3')>,\n",
       "  <Requirement('protobuf==3.5.2.post1')>,\n",
       "  <Requirement('six==1.11.0')>,\n",
       "  <Requirement('tensorboard==1.8.0')>,\n",
       "  <Requirement('tensorflow==1.8.0')>,\n",
       "  <Requirement('termcolor==1.1.0')>,\n",
       "  <Requirement('werkzeug==0.14.1')>,\n",
       "  <Requirement('wheel==0.31.1')>],\n",
       " {'absl-py': ['tensorflow'],\n",
       "  'astor': ['tensorflow'],\n",
       "  'bleach': ['tensorboard'],\n",
       "  'click': ['flask'],\n",
       "  'flask': [],\n",
       "  'gast': ['tensorflow'],\n",
       "  'grpcio': ['tensorflow'],\n",
       "  'html5lib': ['bleach', 'tensorboard'],\n",
       "  'itsdangerous': ['flask'],\n",
       "  'jinja2': ['flask'],\n",
       "  'markdown': ['tensorboard'],\n",
       "  'markupsafe': ['jinja2'],\n",
       "  'numpy': ['tensorboard', 'tensorflow'],\n",
       "  'protobuf': ['tensorboard', 'tensorflow'],\n",
       "  'six': ['absl-py',\n",
       "   'bleach',\n",
       "   'grpcio',\n",
       "   'html5lib',\n",
       "   'protobuf',\n",
       "   'tensorboard',\n",
       "   'tensorflow'],\n",
       "  'tensorboard': ['tensorflow'],\n",
       "  'tensorflow': [],\n",
       "  'termcolor': ['tensorflow'],\n",
       "  'werkzeug': ['flask', 'tensorboard'],\n",
       "  'wheel': ['tensorboard', 'tensorflow']})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requirements, graph = execute_pip_compile(*parsed_requirements)\n",
    "\n",
    "requirements, graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now as we have a graph of dependencies that is serialized into a dictionary, we can ask which package introduced which package as a dependency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "\n",
    "def find_roots(graph, package_name):\n",
    "    assert package_name in graph, f\"The requested package {package_name} does not occur in the dependency graph {graph}\"\n",
    "    \n",
    "    result = deque()\n",
    "    queue = deque([(package_name, [])])\n",
    "    while queue:\n",
    "        package_name, traversed = queue.pop()\n",
    "        ancestors = graph.get(package_name)\n",
    "        \n",
    "        if not ancestors:\n",
    "            if traversed:\n",
    "                result.append(traversed)\n",
    "            continue\n",
    "        \n",
    "        for ancestor in ancestors:\n",
    "            queue.append((ancestor, traversed + [ancestor]))\n",
    "\n",
    "    return list(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['tensorflow'],\n",
       " ['tensorboard', 'tensorflow'],\n",
       " ['protobuf', 'tensorflow'],\n",
       " ['protobuf', 'tensorboard', 'tensorflow'],\n",
       " ['html5lib', 'tensorboard', 'tensorflow'],\n",
       " ['html5lib', 'bleach', 'tensorboard', 'tensorflow'],\n",
       " ['grpcio', 'tensorflow'],\n",
       " ['bleach', 'tensorboard', 'tensorflow'],\n",
       " ['absl-py', 'tensorflow']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Werkzeug is a dependency of flask directly and tensorflow via tensorboard\n",
    "\n",
    "find_roots(graph, 'six')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Requirement('tensorflow')>, <Requirement('flask>=1.0')>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the initial recommendation function we check packages against our knowledge base and based on recommendation type, we eigher allow resolved package to be present in the final software stack or simply exclude it from the final application software stack:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from copy import copy\n",
    "from thoth.solver.exceptions import ThothPipCompileError\n",
    "\n",
    "\n",
    "def _get_version(package_name, pinned_requirements):\n",
    "    for requirement in pinned_requirements:\n",
    "        if requirement.name == package_name:\n",
    "            return str(requirement).split('==', maxsplit=1)[1]\n",
    "\n",
    "    raise ValueError\n",
    "\n",
    "def exclude_requirement(requirement: Requirement,\n",
    "                        requirements: typing.List[Requirement],\n",
    "                        pinned_requirements: typing.List[Requirement],\n",
    "                        dependency_graph: dict) -> typing.List[Requirement]:\n",
    "    candidates = []\n",
    "\n",
    "    requirement_version = str(requirement).split('==', maxsplit=1)[1]\n",
    "    new_requirements = list(requirements)\n",
    "    new_requirements.append(Requirement(f\"{requirement.name}!={requirement_version}\"))\n",
    "    candidates.append(new_requirements)\n",
    "    \n",
    "    # Also all transitive requirements.\n",
    "    packages = find_roots(dependency_graph, requirement.name)\n",
    "    for package in set(chain(*packages)):\n",
    "        package_version = _get_version(package, pinned_requirements)\n",
    "        new_requirements = list(requirements)\n",
    "        new_requirements.append(Requirement(f\"{package}!={package_version}\"))\n",
    "        candidates.append(new_requirements)\n",
    "\n",
    "    return candidates\n",
    "    \n",
    "    \n",
    "\n",
    "def recommend(requirements: typing.List[str], recommendation_type: RecommendationType=RecommendationType.TESTING) -> typing.List[str]:\n",
    "    info = {}\n",
    "    requirements = parse_requirements(requirements)\n",
    "\n",
    "    if recommendation_type == RecommendationType.LATEST:\n",
    "        # Early stop for LATEST\n",
    "        return {'stacks': [requirements], 'info': \"Warning: observations were not considered when LATEST is used\"}\n",
    "\n",
    "    stacks = []\n",
    "    queue = deque([requirements])\n",
    "    while queue:\n",
    "        requirements = queue.pop()\n",
    "\n",
    "        _LOGGER.info(f\"New resolution run for requirements: {[str(req) for req in requirements]}\")\n",
    "\n",
    "        try:\n",
    "            pinned_requirements, dependency_graph = execute_pip_compile(*requirements)\n",
    "        except ThothPipCompileError as exc:\n",
    "            _LOGGER.warning(f\"Requirement specification was invalid: {[str(req) for req in requirements]}: {str(exc)}\")\n",
    "            continue\n",
    "\n",
    "        for requirement in pinned_requirements:\n",
    "            is_ok = KNOWLEDGE_BASE.get(str(requirement))\n",
    "\n",
    "            if is_ok is None and recommendation_type == RecommendationType.TESTING:\n",
    "                info[str(requirement)] = \"Warning: No observations found\"\n",
    "            elif (is_ok is None and recommendation_type == RecommendationType.STABLE) or is_ok is False:\n",
    "                justification = \"Package excluded - negative observations found in the knowledge database\" if is_ok is False else \"Package excluded - no observations found in the knowledge database\"\n",
    "                info[str(requirement)] = justification\n",
    "                candidates = exclude_requirement(\n",
    "                    requirement,\n",
    "                    requirements,\n",
    "                    pinned_requirements,\n",
    "                    dependency_graph,\n",
    "                )\n",
    "                queue.extend(candidates)\n",
    "                break\n",
    "        else:\n",
    "            stacks.append(pinned_requirements)\n",
    "\n",
    "    return {'stacks': list(map(lambda s: [str(req) for req in s], stacks)), 'info': info}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's resolve a software stack for our requirements. In this case we allow potentially unstable environment - recommendation type is `TESTING`. We produce a warning as we do not have any information about `tensorflow` in version `1.8.0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:New resolution run for requirements: ['tensorflow', 'flask>=1.0']\n",
      "INFO:__main__:New resolution run for requirements: ['tensorflow', 'flask>=1.0', 'tensorflow!=1.8.0']\n",
      "INFO:__main__:New resolution run for requirements: ['tensorflow', 'flask>=1.0', 'tensorboard!=1.8.0']\n",
      "WARNING:__main__:Requirement specification was invalid: ['tensorflow', 'flask>=1.0', 'tensorboard!=1.8.0']: pip-compile returned non-zero (2) output: Could not find a version that matches tensorboard!=1.8.0,<1.9.0,>=1.8.0\n",
      "Tried: 1.0.0a3, 1.0.0a4, 1.0.0a5, 1.0.0a6, 1.6.0rc0, 1.6.0, 1.7.0, 1.8.0\n",
      "There are incompatible versions in the resolved dependencies.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.45 s, sys: 14.6 ms, total: 2.46 s\n",
      "Wall time: 2.47 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'info': {'tensorboard==1.8.0': 'Package excluded - negative observations found in the knowledge database',\n",
       "  'tensorflow==1.7.1': 'Warning: No observations found'},\n",
       " 'stacks': [['absl-py==0.2.2',\n",
       "   'astor==0.6.2',\n",
       "   'bleach==1.5.0',\n",
       "   'click==6.7',\n",
       "   'flask==1.0.2',\n",
       "   'gast==0.2.0',\n",
       "   'grpcio==1.12.0',\n",
       "   'html5lib==0.9999999',\n",
       "   'itsdangerous==0.24',\n",
       "   'jinja2==2.10',\n",
       "   'markdown==2.6.11',\n",
       "   'markupsafe==1.0',\n",
       "   'numpy==1.14.3',\n",
       "   'protobuf==3.5.2.post1',\n",
       "   'six==1.11.0',\n",
       "   'tensorboard==1.7.0',\n",
       "   'tensorflow==1.7.1',\n",
       "   'termcolor==1.1.0',\n",
       "   'werkzeug==0.14.1',\n",
       "   'wheel==0.31.1']]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "recommend(['flask>=1.0', 'tensorflow'], RecommendationType.TESTING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's assume we would like to have a stable environment - recommendation type is `STABLE`. In this case package `tensorflow` in version `1.8.0` gets explicitly excluded due to unavailability of observations causing new resolution rounds. The next resolution suggests to use `tensorflow` in version `1.7.1` for which we have negative observations (probably there were spotted issues in the given environment). The next resolution round thus fallbacks to use `tensorflow` in version `1.7.0` that is the stable software stack based on our knowladge base:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:New resolution run for requirements: ['tensorflow', 'flask>=1.0']\n",
      "INFO:__main__:New resolution run for requirements: ['tensorflow', 'flask>=1.0', 'tensorflow!=1.8.0']\n",
      "INFO:__main__:New resolution run for requirements: ['tensorflow', 'flask>=1.0', 'tensorflow!=1.8.0', 'tensorflow!=1.7.1']\n",
      "INFO:__main__:New resolution run for requirements: ['tensorflow', 'flask>=1.0', 'tensorboard!=1.8.0']\n",
      "WARNING:__main__:Requirement specification was invalid: ['tensorflow', 'flask>=1.0', 'tensorboard!=1.8.0']: pip-compile returned non-zero (2) output: Could not find a version that matches tensorboard!=1.8.0,<1.9.0,>=1.8.0\n",
      "Tried: 1.0.0a3, 1.0.0a4, 1.0.0a5, 1.0.0a6, 1.6.0rc0, 1.6.0, 1.7.0, 1.8.0\n",
      "There are incompatible versions in the resolved dependencies.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.97 s, sys: 14.7 ms, total: 2.99 s\n",
      "Wall time: 3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'info': {'tensorboard==1.8.0': 'Package excluded - negative observations found in the knowledge database',\n",
       "  'tensorflow==1.7.1': 'Package excluded - no observations found in the knowledge database'},\n",
       " 'stacks': [['absl-py==0.2.2',\n",
       "   'astor==0.6.2',\n",
       "   'bleach==1.5.0',\n",
       "   'click==6.7',\n",
       "   'flask==1.0.2',\n",
       "   'gast==0.2.0',\n",
       "   'grpcio==1.12.0',\n",
       "   'html5lib==0.9999999',\n",
       "   'itsdangerous==0.24',\n",
       "   'jinja2==2.10',\n",
       "   'markdown==2.6.11',\n",
       "   'markupsafe==1.0',\n",
       "   'numpy==1.14.3',\n",
       "   'protobuf==3.5.2.post1',\n",
       "   'six==1.11.0',\n",
       "   'tensorboard==1.7.0',\n",
       "   'tensorflow==1.7.0',\n",
       "   'termcolor==1.1.0',\n",
       "   'werkzeug==0.14.1',\n",
       "   'wheel==0.31.1']]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "recommend(['flask>=1.0', 'tensorflow'], RecommendationType.STABLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:**\n",
    " * mention that observations are per environment - might differ on Fedora26, Fedora27, ...\n",
    " * mention that we need to inspect software stack in overall - how the given software stack works as a unit\n",
    "   * as there is large amount of possible software stacks (given the package versions and packages themselves), we could train a model for this and perform predictions\n",
    " * we will need to restrict versions on direct dependencies - we need to know which direct dependency introduced the given dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
